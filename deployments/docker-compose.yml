version: '3.4'
name: sms-gateway

x-app-environments: &app-environments
    DB_CONNECTION: postgres
    DB_HOST: pg
    DB_PORT: 5432
    ANALYTICS_DB_CONNECTION: clickhouse
    ANALYTICS_DB_HOST: ch
    ANALYTICS_DB_PORT: 9000
    KAFKA_BROKERS: "kafka:9092"
    REDIS_HOST: redis
    REDIS_PORT: 6379

services:
    sms-server:
        build:
            context: ..
            dockerfile: ./deployments/sms-server.Dockerfile
        environment: *app-environments
        depends_on:
            pg:
                condition: service_healthy
            ch:
                condition: service_started
            kafka:
                condition: service_started
            migrator:
                condition: service_started
            wallet-worker:
                condition: service_started
            redis:
                condition: service_healthy
        ports:
            - 3030:3000

    wallet-worker:
        build:
            context: ..
            dockerfile: ./deployments/wallet-worker.Dockerfile
        environment:
            <<: *app-environments
            CONSUMER_COUNT: 25
        depends_on:
            pg:
                condition: service_healthy
            redis:
                condition: service_healthy
            kafka:
                condition: service_started
            migrator:
                condition: service_started

    queue-worker-regular: &queue-worker
        build:
            context: ..
            dockerfile: ./deployments/queue-worker.Dockerfile
        environment:
            <<: *app-environments
            TOPIC: ${KAFKA_TOPIC_REGULAR}
        depends_on:
            pg:
                condition: service_healthy
            ch:
                condition: service_started
            kafka:
                condition: service_started
            migrator:
                condition: service_started
            wallet-worker:
                condition: service_started

    queue-worker-express-1:
        <<: *queue-worker
        environment:
            <<: *app-environments
            TOPIC: ${KAFKA_TOPIC_EXPRESS}

    queue-worker-express-2:
        <<: *queue-worker
        environment:
            <<: *app-environments
            TOPIC: ${KAFKA_TOPIC_EXPRESS}

    migrator:
        build:
            context: ..
            dockerfile: ./deployments/migrator.Dockerfile
        environment:
            DB_CONNECTION: postgres
            DB_HOST: pg
            DB_PORT: 5432
            ANALYTICS_DB_CONNECTION: clickhouse
            ANALYTICS_DB_HOST: ch
            ANALYTICS_DB_PORT: 9000
            KAFKA_BROKERS: "kafka:9092"
        depends_on:
            pg:
                condition: service_healthy
            ch:
                condition: service_started
            kafka:
                condition: service_started

    pg:
        image: postgres:18-alpine
        environment:
            POSTGRES_USER: ${DB_USERNAME}
            POSTGRES_PASSWORD: ${DB_PASSWORD}
            PGDATA: /data/postgres
            POSTGRES_DB: ${DB_NAME}
        volumes:
            - postgres_data:/data/postgres
        ports:
            - '5332:5432'
        healthcheck:
            test: ['CMD-SHELL', 'pg_isready -d postgres']
            interval: 30s
            timeout: 10s
            retries: 5

    redis:
        image: redis:8-alpine
        ports:
            - '6380:6379'
        volumes:
            - redis_data:/data
        healthcheck:
            test: ["CMD", "redis-cli", "ping"]
            interval: 10s
            timeout: 5s
            retries: 5

    ch-keeper:
        image: clickhouse/clickhouse-keeper:25.8
        ports:
            - '9182:9181'
        volumes:
            - ./clickhouse/keeper_config.xml:/etc/clickhouse-keeper/keeper_config.xml
        healthcheck:
            test: ['CMD', 'nc', '-z', 'ch-keeper', '9181']
            interval: 5s
            retries: 10

    ch:
        image: clickhouse/clickhouse-server:25.8
        environment:
            CLICKHOUSE_DB: ${ANALYTICS_DB_NAME}
            CLICKHOUSE_USER: ${ANALYTICS_DB_USERNAME}
            CLICKHOUSE_PASSWORD: ${ANALYTICS_DB_PASSWORD}
            CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT: 1
        volumes:
            - clickhouse_data:/var/lib/clickhouse
            - ./clickhouse/config.d:/etc/clickhouse-server/config.d
        ports:
            - '9090:9000'
        depends_on:
            ch-keeper:
                condition: service_healthy

    kafka:
        image: apache/kafka:4.1.0
        environment:
            KAFKA_BROKER_ID: 1
            KAFKA_KRAFT_MODE: 'true'
            KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,EXTERNAL://0.0.0.0:9094,CONTROLLER://0.0.0.0:9093
            KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,EXTERNAL://127.0.0.1:9094
            KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT
            KAFKA_PROCESS_ROLES: broker,controller
            KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
            KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'false'
        volumes:
            - kafka_data:/var/lib/kafka/data
        ports:
            - '9094:9094'

    init-kafka-topics:
        image: apache/kafka:4.1.0
        environment:
            TOPIC_REGULAR: ${KAFKA_TOPIC_REGULAR}
            TOPIC_REGULAR_PARTITIONS: ${TOPIC_REGULAR_PARTITIONS:-2}
            TOPIC_EXPRESS: ${KAFKA_TOPIC_EXPRESS}
            TOPIC_EXPRESS_PARTITIONS: ${TOPIC_EXPRESS_PARTITIONS:-20}
            TOPIC_BALANCE: ${KAFKA_TOPIC_BALANCE}
            TOPIC_BALANCE_PARTITIONS: ${TOPIC_BALANCE_PARTITIONS:-50}
            KAFKA_SERVER: "kafka:9092"
        depends_on:
            - kafka
        entrypoint: [ '/bin/sh', '-c' ]
        command: |
            "
            cd /opt/kafka/bin/;

            echo -e 'Waiting for cluster...'
            until ./kafka-cluster.sh cluster-id --bootstrap-server $${KAFKA_SERVER} >/dev/null 2>&1; do
                echo 'Kafka not ready, retrying...'
                sleep 2
            done

            echo -e 'Creating kafka topics...'
            ./kafka-topics.sh --create --topic $${TOPIC_REGULAR} --bootstrap-server $${KAFKA_SERVER} --partitions $${TOPIC_REGULAR_PARTITIONS} --replication-factor 1 --config retention.ms=3600000;
            ./kafka-topics.sh --create --topic $${TOPIC_EXPRESS} --bootstrap-server $${KAFKA_SERVER} --partitions $${TOPIC_EXPRESS_PARTITIONS} --replication-factor 1 --config retention.ms=3600000;
            ./kafka-topics.sh --create --topic $${TOPIC_BALANCE} --bootstrap-server $${KAFKA_SERVER} --partitions $${TOPIC_BALANCE_PARTITIONS} --replication-factor 1 --config retention.ms=3600000;

            echo -e 'Creating internal topic: __consumer_offsets...'
            ./kafka-topics.sh --create --topic __consumer_offsets --bootstrap-server $${KAFKA_SERVER} --partitions 25 --replication-factor 1;

            echo -e 'Successfully created the following topics:'
            ./kafka-topics.sh --bootstrap-server $${KAFKA_SERVER} --list
            "

volumes:
    clickhouse_data:
        driver: local
    postgres_data:
        driver: local
    kafka_data:
        driver: local
    redis_data:
        driver: local
